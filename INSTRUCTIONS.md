# ğŸ™ï¸ AI Voice Detection API - Instructions & Documentation

This project is a ğŸš€ REST API built with FastAPI that uses ğŸ§  heuristic-based audio signal processing to distinguish between human voices and AI-generated speech. It specifically supports **Tamil, English, Hindi, Malayalam, Telugu, and Bengali**.

## ğŸš€ Setup and Execution

1.  **ğŸ“¦ Dependencies**:
    Ensure you have Python 3.10+ and FFmpeg installed. Navigate to the `backend` directory first.
    ```powershell
    cd backend
    pip install -r requirements.txt
    ```

2.  **ğŸ”‘ Environment Variables**:
    Configure your API keys in the `backend/.env` file:
    ```env
    API_KEYS=sk_test_123456789,sk_prod_987654321
    ```

3.  **âš¡ Running the Server**:
    Run from the `backend` directory.
    ```powershell
    cd backend
    # Runs on port 8000 by default (using python -m for reliability)
    python -m uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
    ```

4.  **ğŸ§ª Testing**:
    Use the provided test script from the `backend` directory:
    ```powershell
    cd backend
    python run_and_test.py --audio samples/audio_test.mp3 --language Tamil
    ```
    To run automated unit tests:
    ```powershell
    python -m pytest tests/test_api.py -v
    ```

---

## ğŸ¨ Frontend Dashboard (Project Demo)

A modern, web-based dashboard is provided in the `frontend/` directory. You can access the live version here:
**ğŸ”— [https://voice-shield.vercel.app/](https://voice-shield.vercel.app/)**

### **ğŸ› ï¸ How to use the Dashboard:**
1.  **ğŸ”Œ Ensure your API server is running** (`port 8000`).
2.  **ğŸŒ Open [frontend/index.html](frontend/index.html)** directly in your web browser (Chrome/Edge recommended).
3.  **ğŸ“¤ Upload** an MP3 file (drag and drop or click).
4.  **ğŸ” Click Check Voice**.

---

## ğŸ§ª API Testing Guide

### **ğŸ“ Standard Request Format (JSON)**
When testing via Swagger ([http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)) or external testers:

**âœ‰ï¸ Headers:**
*   `x-api-key`: `sk_test_123456789`
*   `Content-Type`: `application/json`

**ğŸ“¥ Body:**
```json
{
  "language": "Tamil",
  "audioFormat": "mp3",
  "audioBase64": "PASTE_YOUR_FULL_BASE64_STRING_HERE"
}
```

### **ğŸ”§ Common Troubleshooting**
*   **âš ï¸ Command Not Found**: If commands like `uvicorn` or `pytest` result in "command not found," prefix them with `python -m` (e.g., `python -m uvicorn ...`). This is common on Windows when the Python Scripts folder isn't in your PATH.
*   **ğŸ¬ FFmpeg Not Found**: If you see a `RuntimeWarning: Couldn't find ffmpeg`, ensure FFmpeg is installed and added to your system's PATH.
*   **âš ï¸ 400 Bad Request**: Ensure your `audioBase64` string does not contain spaces or newlines.
*   **ğŸš« 401 Unauthorized**: Check that the `x-api-key` header is present and exactly matches the key in your `.env`.
*   **âŒ Method Not Allowed**: Ensure you are using **POST**, not GET, for the `/voice-detection` endpoint.
*   **ğŸ“¡ Connection Error**: If using an external portal, you must deploy your API to a public URL (e.g., via Render or ngrok).

---

## ğŸ“ Project Structure & File Functions

### 1. âš™ï¸ `backend/app/` (Core Application)
*   **ğŸ“„ [backend/app/main.py](backend/app/main.py)**: The entry point of the API.
*   **ğŸ“„ [backend/app/routes.py](backend/app/routes.py)**: Defines the API endpoints.
*   **ğŸ“„ [backend/app/config.py](backend/app/config.py)**: Central configuration file.
*   **ğŸ“„ [backend/app/schemas.py](backend/app/schemas.py)**: Pydantic models for validation.

### 2. ğŸ§  `backend/app/models/` (Logic Layer)
*   **ğŸ“„ [backend/app/models/voice_detector.py](backend/app/models/voice_detector.py)**: The "brain" of the project.

### 3. ğŸ“‰ `backend/app/utils/` (Heuristics & Processing)
*   **ğŸ“„ [backend/app/utils/audio_processor.py](backend/app/utils/audio_processor.py)**: Audio processing logic.

### 4. ğŸ› ï¸ Backend Utilities
*   **ğŸ“„ [backend/run_and_test.py](backend/run_and_test.py)**: Diagnostic CLI tool.
*   **ğŸ“„ [backend/debug_test.py](backend/debug_test.py)**: Raw feature score viewer.
*   **ğŸ“ [backend/samples/](backend/samples/)**: Directory containing audio samples for testing.
*   **ï¿½ğŸ“„ [backend/requirements.txt](backend/requirements.txt)**: Dependency list.
*   **ğŸ“„ [backend/.env](backend/.env)**: Environment configuration.


---

## ğŸ” How Detection Works

The API uses an **ğŸ§  Enhanced Heuristic Model** rather than a simple black-box ML model. It looks for:
*   **ğŸ¤– AI Indicators**: Low pitch variance, "too perfect" harmonic structures, and robotic micro-variations.
*   **ğŸ‘¨â€ğŸ’¼ Human Indicators**: High pitch range, natural breathing pauses, and rich spectral dynamics.

Each characteristic is weighted, and the final score (0.0 to 1.0) determines the classification.

---

## âš–ï¸ License
This software is shared under the **ğŸ“„ MIT License**. You are free to use, modify, and distribute it.
